âœ‹ FingerTrack â€“ Air Writing Letter Recognition using AI

FingerTrack is an AI-powered computer vision project that recognizes letters written in the air using finger movements captured through a webcam. The system tracks finger motion in real time, converts it into an image, and predicts the written letter using a deep learning model.

This project demonstrates practical skills in Computer Vision, Machine Learning, and Humanâ€“Computer Interaction.

ğŸš€ Key Features
âœï¸ Air-writing using index finger (no touch required)
ğŸ– Real-time hand & finger tracking using MediaPipe
ğŸ§  Automatic image generation from finger paths
ğŸ”¤ Letter recognition using CNN (TensorFlow / Keras)
ğŸ“Š Confidence-based prediction output
ğŸ’» Runs in real time using a standard webcam

ğŸ§  Technologies Used
Python
OpenCV
MediaPipe
TensorFlow / Keras
NumPy

ğŸ“ Project Structure
FingerTrack/
â”œâ”€â”€ data.py              # Collects finger-traced letter images
â”œâ”€â”€ train_model.py       # Trains CNN model on collected data
â”œâ”€â”€ m.py                 # Real-time letter prediction
â”œâ”€â”€ set/                 # Auto-generated training images (ignored in GitHub)
â”œâ”€â”€ models/              # Auto-generated trained model (ignored in GitHub)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

âš™ï¸ How It Works

Data Collection
User writes letters in the air using finger movement.
Motion path is captured and converted into grayscale images.
Model Training
A CNN model is trained on the generated images.
The trained model is saved for later use.
Prediction
The system predicts the written letter in real time.
Displays predicted character with confidence score.

â–¶ï¸ How to Run the Project
1ï¸âƒ£ Install dependencies
pip install -r requirements.txt
2ï¸âƒ£ Collect training data
python data.py
Write at least 2 different letters for training.
3ï¸âƒ£ Train the model
python train_model.py
4ï¸âƒ£ Run real-time prediction
python m.py

ğŸ“Œ Notes
The set/ and models/ folders are generated automatically.
These folders are excluded from GitHub using .gitignore.
A webcam is required for real-time input.

ğŸ¯ Applications

Touchless handwriting recognition
Assistive technology
Gesture-based input systems
AI-powered educational tools

ğŸ‘©â€ğŸ’» Author

Miruthula Sakthivel
Aspiring Data Scientist | AI & Computer Vision Enthusiast

ğŸ“œ License
This project is licensed under the MIT License.
